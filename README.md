# Compiling and running llama.cpp on AMD Ryzen 9845HS Fedora 43

Some notes and scripts to enable me to run https://github.com/ggml-org/llama.cpp on my AMD hardware.

After some effort llama.cpp runs very well and I get about 20 TPS using model:

*mradermacher_Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated-i1-GGUF_Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated.i1-Q6_K.gguf*

from Huggingface  `https://huggingface.co/`
